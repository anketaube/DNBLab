{"cells":[{"metadata":{"nbpresent":{"id":"d0d72cd5-034d-4b94-a4e2-54f7753cb9f0"}},"cell_type":"markdown","source":"# DNBLab Jupyter Notebook Tutorial"},{"metadata":{"nbpresent":{"id":"558898c3-e162-4e46-92d5-b4c914325790"}},"cell_type":"markdown","source":"## Digitalisierte Inhaltsverzeichnisse: Datenabfrage, Auslieferung und Volltextanalyse"},{"metadata":{"nbpresent":{"id":"ee78241c-36e7-45e6-b015-0ef46f1e777d"}},"cell_type":"markdown","source":"Dieses DNBLab-Tutorial beschreibt eine Beispielabfrage zu digitalisierten Inhaltsverzeichnissen über die SRU-Schnittstelle und umfasst das temporäre Speichern der Inhaltsverzeichnisse als Textdateien sowie die Analyse der Volltexte nach \n\n* [1. Häufigkeit eines beliebigen Suchwortes](#Teil1)\n* [2. Vorkommen des Suchwortes in den einzelnen Textdateien](#Teil2)\n* [3. Top häufigste Wörter in den Textdateien](#Teil3)\n"},{"metadata":{"nbpresent":{"id":"3c6f6024-cb7c-4b65-8646-a753069cb5a4"}},"cell_type":"markdown","source":"## Einrichten der Arbeitsumgebung\n\nUm die Arbeitsumgebung für die folgenden Schritte passend einzurichten, sollten zunächst die benötigten Python-Bibliotheken importiert werden. Für Anfragen über die SRU-Schnittstelle wird BeautifulSoup https://www.crummy.com/software/BeautifulSoup/ und zur Verarbeitung der XML-Daten etree https://docs.python.org/3/library/xml.etree.elementtree.html verwendet. Mit Pandas https://pandas.pydata.org/ können Elemente aus dem MARC21-Format ausgelesen werden. In der Jupyter Notebook Umgebung kann der dokumentierte Code direkt ausgeführt und angepasst werden."},{"metadata":{"trusted":true},"cell_type":"code","source":"import requests\nfrom bs4 import BeautifulSoup as soup\nimport unicodedata\nfrom lxml import etree\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SRU-Abfrage mit Ausgabe in MARC21-xml\n\nDie Funktion dnb_sru nimmt den Paramter \"query\" der SRU-Abfrage entgegen und liefert alle Ergebnisse als eine Liste von Records aus. Bei mehr als 100 Records werden weitere Datensätze mit \"&startRecord=101\" abgerufen (mögliche Werte 1 bis 99.000). Weitere Informationen und Funktionen der SRU- Schnittstelle werden unter https://www.dnb.de/sru beschrieben."},{"metadata":{"trusted":true},"cell_type":"code","source":"def dnb_sru(query):\n    \n    base_url = \"https://services.dnb.de/sru/dnb\"\n    params = {'recordSchema' : 'MARC21-xml',\n          'operation': 'searchRetrieve',\n          'version': '1.1',\n          'maximumRecords': '100',\n          'query': query\n         }\n    r = requests.get(base_url, params=params)\n    xml = soup(r.content)\n    records = xml.find_all('record', {'type':'Bibliographic'})\n    \n    if len(records) < 100:\n        \n        return records\n    \n    else:\n        \n        num_results = 100\n        i = 101\n        while num_results == 100:\n            \n            params.update({'startRecord': i})\n            r = requests.get(base_url, params=params)\n            xml = soup(r.content)\n            new_records = xml.find_all('record', {'type':'Bibliographic'})\n            records+=new_records\n            i+=100\n            num_results = len(new_records)\n            \n        return records","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Durchsuchen eines MARC-Feldes\n\nDie Funktion parse_records nimmt als Parameter jeweils ein Record entgegen und sucht über xpath die gewünschte Informationen heraus und liefert diese als Dictionary zurück. Die Schlüssel-Werte-Paare können beliebig agepasst und erweitert werden. In diesem Fall werden nur die Permalinks zu den digitalisierten Inhaltsverzeichnissen als \"link\" ausgegeben."},{"metadata":{"trusted":true},"cell_type":"code","source":"def parse_record(record):\n    \n    ns = {\"marc\":\"http://www.loc.gov/MARC21/slim\"}\n    xml = etree.fromstring(unicodedata.normalize(\"NFC\", str(record)))\n    \n    #link\n    link = xml.xpath(\"marc:datafield[@tag = '856']/marc:subfield[@code = 'u']\", namespaces=ns)\n    \n    try:\n        link = link[0].text\n    except:\n        link = \"unkown\"\n        \n    meta_dict = {\"link\":link + '/text'}\n    \n    return meta_dict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Über verschiedenen Indices https://services.dnb.de/sru/dnb?operation=explain&version=1.1 kann die SRU-Abfrage \"dnb_sru\" mittels CQL https://www.dnb.de/DE/Service/Hilfe/Katalog/kataloghilfeExpertensuche.html eingeschränkt werden. Im Folgenden Code wird die Abfrage über das Stichwort \"Sandwespe\" im Volltextindex der digitalisierten Inhaltsverzeichnisse eingeschränkt. Durch Anpassen der SRU-Abfrage kann die Trefferliste beliebig geändert werden."},{"metadata":{"trusted":true},"cell_type":"code","source":"records = dnb_sru('inh=Sandwespe')\nprint(len(records), 'Ergebnisse')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Beispielanzeige zur weiteren Bearbeitung\n\nMit der Bibliothek Pandas für Python wird das Ergebnis (Dictionary-Element \"link\") als Dataframe ausgegeben."},{"metadata":{"trusted":true},"cell_type":"code","source":"output = [parse_record(record) for record in records]\ndf = pd.DataFrame(output)\ndf\n\n#Die Ausgabe der ermittelten Links kann je nach Bedarf über verschiedene Funktionen erfolgen:\n#print(df.to_string(index=False))\n#HTML(df.to_html(index=False))\n#document = df.to_dict(orient='list')\n#print(document)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Download der Textdateien \n\nMit der folgenden Funktion df.to_csv() werden die Ergebnisse als \"links.csv\" in das Jupyter-Verzeichnins der Einstiegsseite abgelegt und können dort heruntergeladen werden. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv(\"links.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mit wget werden alle in der CSV-Datei gespeicherten Links heruntergeladen und als Textdateien (text, text.1, text.2, usw.) im temporären Jupyter-Verzeichnis gespeichert (Downloadlimit 1MB). "},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget -Q1m -i links.csv","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Volltextanalyse \n\n### 1. Häufigkeit eines beliebigen Suchwortes<a class=\"anchor\" id=\"Teil1\"></a>\n\nDie heruntergeladenen Textdateien können nach einem Suchwort, z.B. search = \"biene\" durchsucht werden. Hierbei wird die Groß- und Kleinschreibung beachtet.\nAls Antwort werden die durchsuchten Textdateien genannt und die Häufigkeit des gesuchten Wortes in den genannten Dateien ausgegeben. Dabei entspricht die Dateibenennung den im Verzeichnis heruntergeladen Textdateien (text, text1, text2 usw.).\nDas Suchwort kann beliebig geändert und die Suche durch Ausführen des Codes angepasst werden."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Eingabe des Suchwortes mit Button zur Übernahme der eingegebenen Werte \n\nfrom IPython.display import display \nimport ipywidgets as widgets \nfrom ipywidgets import interact, Layout \n\ntb1 = widgets.Text(value = 'biene', description ='Suchwort: ');display(tb1);\n\n\nbutton = widgets.Button(description='Übernehmen!', layout=Layout(width='200px')); \nbutton.style.button_color='lightgreen';display(button); \ndef on_button_clicked(sender): \n    a = tb1.value; \n    print('Folgendes Suchwort wurde übernommen: ' + str(tb1.value))     \nbutton.on_click(on_button_clicked)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nach Übernahme des Suchworts werden erstmal alle Treffer in den Dateien gezählt und ausgegeben."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Automatische Verarbeitung der Dateinamen\n\ndef adding_name(counter):\n\n    i = 1\n    names = []\n\n    for i in range (1, counter): \n        number = str(i)\n        name = \"text.\" + number\n        names.append(name)\n        i+=1\n    \n    return names \n    \n\n\ncounter = len(records)\n\nvar = adding_name(counter)\nprint(\"Folgende Textdateien wurden durchsucht: \\n text\", *var, sep = \"\\n\") \n\n\n# Suche und Zählen der Zeilen mit Treffern\n\nsearch = str(tb1.value)\nanzahl = 0 \nanzahl2 = 0\n\nfilename = 'text'\nwith open(filename) as f:\n    for num, line in enumerate(f, 1):\n        if search in line:\n            anzahl += 1\n            \nfor name in var: \n    with open(name) as f:\n        for num, line in enumerate(f, 1):\n            if search in line:\n                anzahl2 += 1\n\nprint('Insgesamt wurde das Suchwort', anzahl+anzahl2, \"Mal in den zu durchsuchenden Textdateien gefunden.\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Vorkommen des Suchwortes in den einzelnen Textdateien<a class=\"anchor\" id=\"Teil2\"></a>\n\nAlle Treffer werden mit Angabe der Zeile und Datei ausgegeben. \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"search = str(tb1.value)\nnew_file = open('Trefferliste.txt', 'w')\n\nfilename = 'text'\nwith open(filename) as f:\n    for num, line in enumerate(f, 1):\n        if search in line:\n            print('Das Suchwort \"%s\" wurde gefunden in Zeile:' % search, num , 'in der Datei ',filename)\n            text = ('Das Suchwort \"%s\" wurde gefunden in Zeile:' % search, num , 'in der Datei ',filename)\n            new_file.write(str(text) + \"\\n\")\n            #summary.append(text)\n            \n            \n#Einbau der Schleife erst hier wegen des leicht anderen Formats der Dateinamen... :             \nfor name in var: \n    with open(name) as f:\n        for num, line in enumerate(f, 1):\n            if search in line:\n                print('Das Suchwort \"%s\" wurde gefunden in Zeile:' % search, num , 'in der Datei ',name) \n                text2 = ('Das Suchwort \"%s\" wurde gefunden in Zeile:' % search, num , 'in der Datei ',name)\n                new_file.write(str(text2) + \"\\n\")\n                \nnew_file.close()\n\nwith open('Trefferliste.txt') as f:\n    #lines = f.readlines()\n    result = f.read()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Top häufigste Wörter in den Textdateien<a class=\"anchor\" id=\"Teil3\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}