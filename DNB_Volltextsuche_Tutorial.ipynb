{"cells":[{"metadata":{"nbpresent":{"id":"d0d72cd5-034d-4b94-a4e2-54f7753cb9f0"}},"cell_type":"markdown","source":"# DNBLab Jupyter Notebook Tutorial"},{"metadata":{"nbpresent":{"id":"558898c3-e162-4e46-92d5-b4c914325790"}},"cell_type":"markdown","source":"## Digitalisierte Inhaltsverzeichnisse: Datenabfrage, Auslieferung und Volltextanalyse"},{"metadata":{"nbpresent":{"id":"ee78241c-36e7-45e6-b015-0ef46f1e777d"}},"cell_type":"markdown","source":"Dieses DNBLab-Tutorial beschreibt eine Beispielabfrage zu digitalisierten Inhaltsverzeichnissen über die SRU-Schnittstelle. Das Tutorial umfasst eine exemplarische Abfrage, das temporäre Speichern der Inhaltsverzeichnisse als Textdateien und Durchsuchen der Volltexte nach einem beliebigen Stichwort. In der Jupyter Notebook Umgebung kann der dokumentierte Code direkt ausgeführt und angepasst werden."},{"metadata":{"nbpresent":{"id":"3c6f6024-cb7c-4b65-8646-a753069cb5a4"}},"cell_type":"markdown","source":"## Einrichten der Arbeitsumgebung <a class=\"anchor\" id=\"Teil1\"></a>\n\nUm die Arbeitsumgebung für die folgenden Schritte passend einzurichten, sollten zunächst die benötigten Python-Bibliotheken importiert werden. Für Anfragen über die SRU-Schnittstelle wird BeautifulSoup https://www.crummy.com/software/BeautifulSoup/ und zur Verarbeitung der XML-Daten etree https://docs.python.org/3/library/xml.etree.elementtree.html verwendet. Mit Pandas https://pandas.pydata.org/ können Elemente aus dem MARC21-Format ausgelesen werden."},{"metadata":{"trusted":true},"cell_type":"code","source":"import requests\nfrom bs4 import BeautifulSoup as soup\nimport unicodedata\nfrom lxml import etree\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SRU-Abfrage mit Ausgabe in MARC21-xml<a class=\"anchor\" id=\"Teil2\"></a>\n\nDie Funktion dnb_sru nimmt den Paramter \"query\" der SRU-Abfrage entgegen und liefert alle Ergebnisse als eine Liste von Records aus. Bei mehr als 100 Records werden weitere Datensätze mit \"&startRecord=101\" abgerufen (mögliche Werte 1 bis 99.000). Weitere Informationen und Funktionen der SRU- Schnittstelle werden unter https://www.dnb.de/sru beschrieben."},{"metadata":{"trusted":true},"cell_type":"code","source":"def dnb_sru(query):\n    \n    base_url = \"https://services.dnb.de/sru/dnb\"\n    params = {'recordSchema' : 'MARC21-xml',\n          'operation': 'searchRetrieve',\n          'version': '1.1',\n          'maximumRecords': '100',\n          'query': query\n         }\n    r = requests.get(base_url, params=params)\n    xml = soup(r.content)\n    records = xml.find_all('record', {'type':'Bibliographic'})\n    \n    if len(records) < 100:\n        \n        return records\n    \n    else:\n        \n        num_results = 100\n        i = 101\n        while num_results == 100:\n            \n            params.update({'startRecord': i})\n            r = requests.get(base_url, params=params)\n            xml = soup(r.content)\n            new_records = xml.find_all('record', {'type':'Bibliographic'})\n            records+=new_records\n            i+=100\n            num_results = len(new_records)\n            \n        return records","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Durchsuchen eines MARC-Feldes<a class=\"anchor\" id=\"Teil3\"></a>\n\nDie Funktion parse_records nimmt als Parameter jeweils ein Record entgegen und sucht über xpath die gewünschte Informationen heraus und liefert diese als Dictionary zurück. Die Schlüssel-Werte-Paare können beliebig agepasst und erweitert werden. In diesem Fall werden nur die Permalinks zu den digitalisierten Inhaltsverzeichnissen als \"link\" ausgegeben."},{"metadata":{"trusted":true},"cell_type":"code","source":"def parse_record(record):\n    \n    ns = {\"marc\":\"http://www.loc.gov/MARC21/slim\"}\n    xml = etree.fromstring(unicodedata.normalize(\"NFC\", str(record)))\n    \n    #link\n    link = xml.xpath(\"marc:datafield[@tag = '856']/marc:subfield[@code = 'u']\", namespaces=ns)\n    \n    try:\n        link = link[0].text\n    except:\n        link = \"unkown\"\n        \n    meta_dict = {\"link\":link + '/text'}\n    \n    return meta_dict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Über verschiedenen Indices https://services.dnb.de/sru/dnb?operation=explain&version=1.1 kann die SRU-Abfrage \"dnb_sru\" mittels CQL https://www.dnb.de/DE/Service/Hilfe/Katalog/kataloghilfeExpertensuche.html eingeschränkt werden. Im Folgenden Code wird die Abfrage über das Stichwort \"Sandwespe\" im Volltextindex der digitalisierten Inhaltsverzeichnisse eingeschränkt. Durch Anpassen der SRU-Abfrage kann die Trefferliste beliebig geändert werden."},{"metadata":{"trusted":true},"cell_type":"code","source":"records = dnb_sru('inh=Sandwespe')\nprint(len(records), 'Ergebnisse')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Beispielanzeige zur weiteren Bearbeitung <a class=\"anchor\" id=\"Teil4\"></a>\n\nMit der Bibliothek Pandas für Python wird das Ergebnis (Dictionary-Element \"link\") als Dataframe ausgegeben."},{"metadata":{"trusted":true},"cell_type":"code","source":"output = [parse_record(record) for record in records]\ndf = pd.DataFrame(output)\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Die Ausgabe der ermittelten Links kann je nach Bedarf über verschiedene Funktionen erfolgen:"},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(df.to_string(index=False))\n#HTML(df.to_html(index=False))\n#document = df.to_dict(orient='list')\n#print(document)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mit der folgenden Funktion df.to_csv() werden die Ergebnisse als \"links.csv\" in das Jupyter-Verzeichnins der Einstiegsseite abgelegt und können dort heruntergeladen werden. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv(\"links.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mit wget werden alle in der CSV-Datei gespeicherten Links heruntergeladen und als Textdateien (text, text.1, text.2, usw.) im temporären Jupyter-Verzeichnis gespeichert. "},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget -i links.csv","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Die heruntergeladenen Textdateien können jetzt nach einem Suchwort, z.B. search = \"Wild\" durchsucht werden. Hierbei wird die Groß- und Kleinschreibung beachtet.\nDie Treffer werden mit Angabe der Zeile und Datei ausgegeben. Dabei entspricht die Dateibenennung den im Verzeichnis heruntergeladen Textdateien (text, text1, text2 usw.).\nDas Suchwort kann beliebig geändert und durch Ausführen des Codes die Suche angepasst werden."},{"metadata":{"trusted":true},"cell_type":"code","source":"search = 'biene'\n\nfilename = 'text'\nwith open(filename) as f:\n    for num, line in enumerate(f, 1):\n        if search in line:\n            print('%s - found at line in text:' % search, num)\nfilename2 = 'text.1'\nwith open(filename2) as f:\n    for num, line in enumerate(f, 1):\n        if search in line:\n            print('%s - found at line in text.1:' % search, num)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}